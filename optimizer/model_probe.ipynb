{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.display import HTML\n",
    "import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Inputs must not be empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-168fa63d592f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mlslope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlintercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinregress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlin_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlslope\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlintercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/scipy/stats/_stats_mstats_common.py\u001b[0m in \u001b[0;36mlinregress\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Inputs must not be empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Inputs must not be empty."
     ]
    }
   ],
   "source": [
    "os.system(\"g++ -ffast-math -march=native -O3 measure_linvbin.cpp\")\n",
    "os.system(\"./a.out > bvl.csv\")\n",
    "\n",
    "df = pd.read_csv(\"bvl.csv\", header=None, names=[\"method\", \"err\", \"time\"])\n",
    "df[\"time\"] /= 500000\n",
    "\n",
    "\n",
    "from scipy.stats import linregress\n",
    "x = df[df.method == \"linear\"][\"err\"]\n",
    "y = df[df.method == \"linear\"][\"time\"]\n",
    "\n",
    "lslope, lintercept, lrval, _, _ = linregress(x, y)\n",
    "def lin_mod(x):\n",
    "    return (lslope * x + lintercept).clip(lower=0)\n",
    "\n",
    "assert lrval > 0.98\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x, lin_mod(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = df[df.method == \"binary\"][\"err\"]\n",
    "y = df[df.method == \"binary\"][\"time\"]\n",
    "slope, intercept, rval, _, _ = linregress(np.log(x), y)\n",
    "print(rval)\n",
    "def bin_mod(x):\n",
    "    return (np.log(x) * slope + intercept).clip(lower=0)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x, bin_mod(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "bin_pred = KNeighborsRegressor(n_neighbors=2)\n",
    "bin_pred.fit(df[df.method == \"binary\"][[\"err\"]], df[df.method == \"binary\"][\"time\"])\n",
    "\n",
    "lin_pred = KNeighborsRegressor(n_neighbors=2)\n",
    "lin_pred.fit(df[df.method == \"linear\"][[\"err\"]], df[df.method == \"linear\"][\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_pred.predict([[1]])\n",
    "bin_pred.predict([[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/ryan/SOSD/data/lognormal_200M_uint64\"\n",
    "DATA_FILE = DATA_PATH.split(\"/\")[-1]\n",
    "\n",
    "os.system(\"cd .. && cargo build --release\")\n",
    "RMI_PATH = \"../target/release/rmi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_only_layers = [\"radix\", \"bradix\"]\n",
    "anywhere_layers = [\"linear\", \"cubic\"]\n",
    "specialty_top_layers = [\"histogram\", \"loglinear\", \"normal\", \"lognormal\"]\n",
    "branching_factors = [2**x for x in range(7, 22)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_top_layers = top_only_layers + anywhere_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, build a grid of the most likely configs\n",
    "configs = []\n",
    "nmspc_counter = 0\n",
    "for top in all_top_layers:\n",
    "    for bot in anywhere_layers:\n",
    "        for bf in branching_factors[::3]:\n",
    "            configs.append({\"layers\": f\"{top},{bot}\", \"branching factor\": bf, \"namespace\": f\"nm{nmspc_counter}\"})\n",
    "            nmspc_counter += 1\n",
    "            \n",
    "# next, build a few tests to see if a speciality layer would help\n",
    "for top in specialty_top_layers:\n",
    "    if top == \"histogram\":\n",
    "        for bot in anywhere_layers:\n",
    "            for bf in [64, 128, 256]:\n",
    "                configs.append({\"layers\": f\"{top},{bot}\", \"branching factor\": bf, \"namespace\": f\"nm{nmspc_counter}\"})\n",
    "                nmspc_counter += 1\n",
    "    else:\n",
    "        # not a histogram\n",
    "        for bot in anywhere_layers:\n",
    "            for bf in branching_factors[::4]:\n",
    "                configs.append({\"layers\": f\"{top},{bot}\", \"branching factor\": bf, \"namespace\": f\"nm{nmspc_counter}\"})\n",
    "                nmspc_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_test_rmis(configs, threads=8, phase=\"\", fast_top=False):\n",
    "    if len(configs) < threads:\n",
    "        threads = len(configs)\n",
    "        \n",
    "    os.system(\"rm *.json *.json_results\")\n",
    "    jobs = [[] for _ in range(threads)]\n",
    "    procs = []\n",
    "    \n",
    "    for idx, conf in enumerate(configs):\n",
    "        jobs[idx % threads].append(conf)\n",
    "        \n",
    "    for idx, workset in enumerate(jobs):\n",
    "        fn = f\"{phase}{idx}.json\"\n",
    "        with open(fn, \"w\") as f:\n",
    "            json.dump({\"configs\": workset}, f)\n",
    "        cmd = f\"{RMI_PATH} {DATA_PATH} --param-grid {fn}\"\n",
    "        if fast_top:\n",
    "            cmd += \" --fast-top\"\n",
    "            \n",
    "        procs.append(subprocess.Popen(cmd, shell=True))\n",
    "\n",
    "    print(\"Spawned\", threads, \"processes with\", [len(x) for x in jobs], \"jobs each\")\n",
    "    \n",
    "    retry = []\n",
    "    for idx, proc in enumerate(procs):\n",
    "        if proc.wait() != 0:\n",
    "            print(\"Failure in RMI construction at idx\", idx, \"queued for retry\")\n",
    "            retry.append(idx)\n",
    "           \n",
    "    procs = []\n",
    "    for idx in retry:\n",
    "        fn = f\"{phase}{idx}.json\"\n",
    "        cmd = f\"{RMI_PATH} {DATA_PATH} --param-grid {fn}\"\n",
    "        if fast_top:\n",
    "            cmd += \" --fast-top\"\n",
    "            \n",
    "        procs.append(subprocess.Popen(cmd, shell=True))\n",
    "        \n",
    "    for idx, proc in enumerate(procs):\n",
    "        if proc.wait() != 0:\n",
    "            print(\"Failure in retry of RMI construction at idx\", idx)\n",
    "            print(\"Perhaps lower the thread count?\")\n",
    "            assert False\n",
    "            \n",
    "    os.system(\"sync\")\n",
    "    os.system(\"rm -rf opt/\")\n",
    "    os.system(\"mkdir opt\")\n",
    "    os.system(\"mv nm* opt/\")\n",
    "    data = []\n",
    "    for idx, _ in enumerate(jobs):\n",
    "        fn = f\"{phase}{idx}.json_results\"\n",
    "        with open(fn, \"r\") as f:\n",
    "            data.extend(json.load(f))\n",
    "\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing\", len(configs), \"initial configurations.\")\n",
    "\n",
    "step1_results = parallel_test_rmis(configs, phase=\"step1\", fast_top=True)\n",
    "step1_results = pd.DataFrame(step1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(step1_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystache\n",
    "with open(\"bench.cpp\", \"r\") as f:\n",
    "    template = f.read()\n",
    "    \n",
    "with open(\"to_build.cpp\", \"w\") as f:\n",
    "    f.write(pystache.render(template, \n",
    "                            {\"filename\": DATA_PATH, \n",
    "                             \"namespaces\": step1_results.namespace.tolist()}))\n",
    "    \n",
    "if os.system(\"make -j 40\") != 0:\n",
    "    print(\"Error compiling inference program!\")\n",
    "    \n",
    "os.system(\"./a.out > inference.txt\")\n",
    "with open(\"inference.txt\") as f:\n",
    "    inference = list(int(x.strip()[:-2]) / 100000.0 for x in f)\n",
    "    \n",
    "step1_results[\"inference\"] = inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1_results[\"pred_time_lin\"] = step1_results.inference + lin_pred.predict(step1_results[[\"max error\"]])\n",
    "step1_results[\"pred_time_bin\"] = step1_results.inference + bin_pred.predict(step1_results[[\"max error\"]])\n",
    "step1_results[\"pred_time\"] = step1_results[[\"pred_time_lin\", \"pred_time_bin\"]].min(axis=1)\n",
    "\n",
    "step1_results[\"star\"] = False\n",
    "step1_results.loc[step1_results[\"layers\"] == \"bradix,linear\", \"star\"] = True\n",
    "\n",
    "display(HTML(step1_results.sort_values(\"layers\").to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_mask(df, v1=\"size linear search\", v2=\"pred_time\", soft=True, ignore_star=False):\n",
    "    # find Pareto efficient RMIs\n",
    "    mask = []\n",
    "    for idx1, el1 in df.iterrows():\n",
    "        my_size = el1[v1]\n",
    "        my_time = el1[v2]\n",
    "        starred = el1[\"star\"]\n",
    "        for idx2, el2 in df.iterrows():\n",
    "            if idx1 == idx2:\n",
    "                continue\n",
    "\n",
    "            if ((el2[v1] <= my_size) \n",
    "                and (el2[v2] <= my_time - (10 if soft else 0))):\n",
    "                if (not starred) or ignore_star:\n",
    "                    mask.append(False)\n",
    "                    break\n",
    "        else:\n",
    "            mask.append(True)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pareto_mask(step1_results)\n",
    "pareto = step1_results[mask]\n",
    "print(\"Found\", len(pareto), \"Pareto efficient models\")\n",
    "display(HTML(pareto.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_layers = set(pareto[\"layers\"])\n",
    "next_configs = []\n",
    "for candidate in candidate_layers:\n",
    "    if candidate.startswith(\"histogram\"):\n",
    "        for bf in [32, 300, 512]:\n",
    "            next_configs.append({\"layers\": candidate, \"branching factor\": bf,\n",
    "                                 \"namespace\": f\"nm{nmspc_counter}\"})\n",
    "            nmspc_counter += 1\n",
    "\n",
    "    else:\n",
    "        already_known = step1_results[step1_results.layers == candidate][\"branching factor\"].to_list()\n",
    "        for bf in sorted(set(branching_factors) - set(already_known)):\n",
    "            next_configs.append({\"layers\": candidate, \"branching factor\": bf,\n",
    "                                 \"namespace\": f\"nm{nmspc_counter}\"})\n",
    "            nmspc_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing\", len(next_configs), \"additional configurations.\")\n",
    "\n",
    "step2_results = parallel_test_rmis(next_configs, phase=\"step2\", fast_top=True)\n",
    "step2_results = pd.DataFrame(step2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystache\n",
    "with open(\"bench.cpp\", \"r\") as f:\n",
    "    template = f.read()\n",
    "    \n",
    "with open(\"to_build.cpp\", \"w\") as f:\n",
    "    f.write(pystache.render(template, \n",
    "                            {\"filename\": DATA_PATH, \n",
    "                             \"namespaces\": step2_results.namespace.tolist()}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Compiling...\")\n",
    "os.system(\"make -j 40\")\n",
    "\n",
    "print(\"Executing...\")\n",
    "os.system(\"./a.out > inference.txt\")\n",
    "with open(\"inference.txt\") as f:\n",
    "    inference = list(int(x.strip()[:-2]) / 100000.0 for x in f)\n",
    "    \n",
    "step2_results[\"inference\"] = inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step2_results[\"pred_time_lin\"] = step2_results.inference + lin_pred.predict(step2_results[[\"max error\"]])\n",
    "step2_results[\"pred_time_bin\"] = step2_results.inference + bin_pred.predict(step2_results[[\"max error\"]])\n",
    "step2_results[\"pred_time\"] = step2_results[[\"pred_time_lin\", \"pred_time_bin\"]].min(axis=1)\n",
    "\n",
    "step2_results[\"star\"] = False\n",
    "step2_results.loc[step2_results[\"layers\"] == \"bradix,linear\", \"star\"] = True\n",
    "\n",
    "\n",
    "step2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat((step1_results, step2_results)).reset_index(drop=True)\n",
    "mask = pareto_mask(all_results)\n",
    "all_results.sort_values(\"pred_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(all_results.sort_values(\"layers\").to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_size(bytes, units=[' bytes','KB','MB','GB','TB', 'PB', 'EB']):\n",
    "    \"\"\" Returns a human readable string reprentation of bytes\"\"\"\n",
    "    return str(bytes) + units[0] if bytes < 1024 else human_size(bytes>>10, units[1:])\n",
    "\n",
    "all_hresults = all_results.copy()\n",
    "all_hresults[\"size linear search\"] = [human_size(x) for x in all_results[\"size linear search\"].to_list()]\n",
    "all_hresults[\"size binary search\"] = [human_size(x) for x in all_results[\"size binary search\"].to_list()]\n",
    "all_hresults[mask].sort_values(\"pred_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = all_results.plot.scatter(\"size binary search\", \"pred_time\", color=\"orange\")\n",
    "all_results[mask].plot.scatter(\"size binary search\", \"pred_time\", ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[\"binary\"] = all_results[\"pred_time_lin\"] >= all_results[\"pred_time_bin\"]\n",
    "\n",
    "final_configs = []\n",
    "for idx, row in all_results[mask][[\"layers\", \"branching factor\", \"namespace\", \"binary\"]].iterrows():\n",
    "    final_configs.append(row.to_dict())\n",
    "\n",
    "                         \n",
    "final_results = parallel_test_rmis(final_configs, phase=\"step3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_rmis(configs):\n",
    "    os.system(\"rm -rf SOSD/build\")\n",
    "    os.system(\"rm -rf SOSD/competitors/rmi/nm*\")\n",
    "    for config in configs:\n",
    "        ns = config[\"namespace\"]\n",
    "        os.system(f\"cp opt/{ns}.cpp SOSD/competitors/rmi/\")\n",
    "        os.system(f\"cp opt/{ns}_data.h SOSD/competitors/rmi/\")\n",
    "        os.system(f\"cp opt/{ns}.h SOSD/competitors/rmi/\")\n",
    "        \n",
    "    with open(\"SOSD/benchmark.cc.mustache\", \"r\") as f:\n",
    "        template = f.read()\n",
    "\n",
    "    with open(\"SOSD/benchmark.cc\", \"w\") as f:\n",
    "        f.write(pystache.render(template, \n",
    "                                {\"candidates\": configs}))\n",
    "\n",
    "    os.system(\"cd SOSD && scripts/prepare.sh\")\n",
    "    os.system(f\"cd SOSD && build/benchmark {DATA_PATH} {DATA_PATH}_equality_lookups_10M > times.txt\")\n",
    "\n",
    "    times = []\n",
    "    with open(\"SOSD/times.txt\", \"r\") as f:\n",
    "        for l in f:\n",
    "            if not l.startswith(\"RESULT\"):\n",
    "                continue\n",
    "            if \",\" not in l:\n",
    "                continue\n",
    "            result = l.split(\",\")[1]\n",
    "            if result == \"-1\":\n",
    "                times.append(float(\"NaN\"))\n",
    "            else:\n",
    "                times.append(float(result))\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = measure_rmis(final_configs)\n",
    "tested_results = all_results[mask].copy()\n",
    "tested_results[\"measured\"] = times\n",
    "tested_results.plot.scatter(\"pred_time\", \"measured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_mask = tested_results[\"measured\"].isna()\n",
    "tested_results[failed_mask][[\"layers\", \"branching factor\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mask = pareto_mask(tested_results, v2=\"measured\", soft=False)\n",
    "tested_results[final_mask].plot.scatter(\"size linear search\", \"measured\")\n",
    "tested_results[final_mask].sort_values(\"measured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for idx, r in tested_results.iterrows():\n",
    "    y.append(r.measured)\n",
    "    \n",
    "    features = []\n",
    "    features.append(r[\"inference\"])\n",
    "    if r.binary:\n",
    "        features.append(bin_pred.predict([[r[\"max error\"]]])[0])\n",
    "    else:\n",
    "        features.append(lin_pred.predict([[r[\"max error\"]]])[0])\n",
    "    x.append(features)\n",
    "\n",
    "        \n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(x, y)\n",
    "\n",
    "plt.scatter(tested_results.pred_time, tested_results.measured)\n",
    "plt.scatter(reg.predict(x), tested_results.measured, color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for idx, r in all_results.iterrows():\n",
    "    features = []\n",
    "    features.append(r[\"inference\"])\n",
    "    if r.binary:\n",
    "        features.append(bin_pred.predict([[r[\"max error\"]]])[0])\n",
    "    else:\n",
    "        features.append(lin_pred.predict([[r[\"max error\"]]])[0])\n",
    "    x.append(features)\n",
    "\n",
    "all_results[\"adj pred time\"] = reg.predict(x)\n",
    "new_mask = pareto_mask(all_results, v2=\"adj pred time\")\n",
    "adj_on_front = all_results[new_mask].copy()\n",
    "\n",
    "redo_configs = []\n",
    "adj_mask = []\n",
    "for adj in adj_on_front.T.to_dict().values():\n",
    "    res = tested_results[(tested_results.layers == adj[\"layers\"]) & (tested_results[\"branching factor\"] == adj[\"branching factor\"])]\n",
    "    if len(res) != 1:\n",
    "        adj_mask.append(True)\n",
    "        redo_configs.append({\n",
    "            \"layers\": adj[\"layers\"],\n",
    "            \"branching factor\": adj[\"branching factor\"],\n",
    "            \"namespace\": f\"nm{nmspc_counter}\",\n",
    "            \"binary\": adj[\"max error\"] > 100\n",
    "        })\n",
    "        nmspc_counter += 1\n",
    "    else:\n",
    "        adj_mask.append(False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if redo_configs:\n",
    "    print(len(redo_configs), \"to re-test after updating inference model\")\n",
    "    parallel_test_rmis(redo_configs, phase=\"adj\")\n",
    "    new_times = measure_rmis(redo_configs)\n",
    "    new_results = adj_on_front[adj_mask].copy()\n",
    "    new_results[\"measured\"] = new_times\n",
    "    tested_results = pd.concat((new_results, tested_results), sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mask = pareto_mask(tested_results, v2=\"measured\", ignore_star=True)\n",
    "ax = tested_results.plot.scatter(\"size linear search\", \"measured\", color=\"red\")\n",
    "tested_results[final_mask].plot.scatter(\"size linear search\", \"measured\", ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = tested_results[final_mask].copy()\n",
    "final_results.plot.scatter(\"size linear search\", \"measured\")\n",
    "final_results[\"size\"] = final_results[\"binary\"].astype(np.int) * final_results[\"size binary search\"] + ((final_results[\"binary\"].astype(np.int) + 1) % 2) * final_results[\"size linear search\"]\n",
    "final_results[[\"layers\", \"branching factor\", \"average error\", \"max error\", \"size\", \"measured\"]].sort_values(\"measured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
